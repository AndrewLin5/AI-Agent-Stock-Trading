{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9cc0660-4ae4-49ee-af4e-26e42268513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent AI: To make decision making for the database\n",
    "# Environment for the external system\n",
    "# State is the represetation for the information available: Stock closing prices, moving averages, and daily returns\n",
    "# Action Space for AI Agent's actions: Buy, Sell, and Hold\n",
    "# Reward Function to determine the Agent's preformance by assigning a numerical value for it's actions: total profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d437f6ad-62e3-424b-9a49-fc3a9f4ed871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.61-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.18.1.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 3.0/3.0 MB 58.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.11.1-cp39-abi3-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from yfinance) (4.25.3)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\megaw\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Downloading yfinance-0.2.61-py2.py3-none-any.whl (117 kB)\n",
      "Downloading curl_cffi-0.11.1-cp39-abi3-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 77.0 MB/s eta 0:00:00\n",
      "Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.18.1-py3-none-any.whl size=139097 sha256=5878db1d873098b6724ed978106428babbb66dd658e14a1770a3636459835968\n",
      "  Stored in directory: c:\\users\\megaw\\appdata\\local\\pip\\cache\\wheels\\1a\\57\\6a\\bb71346381d0d911cd4ce3026f1fa720da76707e4f01cf27dd\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, curl_cffi, yfinance\n",
      "Successfully installed curl_cffi-0.11.1 multitasking-0.0.11 peewee-3.18.1 websockets-15.0.1 yfinance-0.2.61\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb1107c-a41f-4005-ad17-b11f393c025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# define a specific stock symbol (Apple in this case) and time period\n",
    "symbol = \"AAPL\"\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-04-01\"\n",
    "\n",
    "# download historical data\n",
    "data = yf.download(symbol, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394fe4d7-b149-483b-8e26-b0adfae0ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Program Technical indicators for better trading decisions\n",
    "# feature engineering\n",
    "data['SMA_5'] = data['Close'].rolling(window=5).mean()\n",
    "data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
    "data['Returns'] = data['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7785f776-8b8a-4138-a967-185d4820b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values and reset index\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80d250c6-fae0-49f9-92a6-d69ca324c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define actions\n",
    "ACTIONS = {0: \"HOLD\", 1: \"BUY\", 2: \"SELL\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a470f0c8-b983-47af-9d20-da6e1853c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the reinforcement training model, we extract with get state function\n",
    "# get state function\n",
    "def get_state(data, index):\n",
    "    return np.array([\n",
    "        float(data.loc[index, 'Close']),\n",
    "        float(data.loc[index, 'SMA_5']),\n",
    "        float(data.loc[index, 'SMA_20']),\n",
    "        float(data.loc[index, 'Returns'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5452e3fe-b4d3-4c1b-9fdb-f8e03a8b71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build trading environment\n",
    "# trading environment\n",
    "class TradingEnvironment:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.initial_balance = 10000\n",
    "        self.balance = self.initial_balance\n",
    "        self.holdings = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.holdings = 0\n",
    "        self.index = 0\n",
    "        return get_state(self.data, self.index)\n",
    "\n",
    "    def step(self, action):\n",
    "        price = float(self.data.loc[self.index, 'Close'])\n",
    "        reward = 0\n",
    "\n",
    "        if action == 1 and self.balance >= price:  # BUY\n",
    "            self.holdings = self.balance // price\n",
    "            self.balance -= self.holdings * price\n",
    "        elif action == 2 and self.holdings > 0:  # SELL\n",
    "            self.balance += self.holdings * price\n",
    "            self.holdings = 0\n",
    "\n",
    "        self.index += 1\n",
    "        done = self.index >= len(self.data) - 1\n",
    "\n",
    "        if done:\n",
    "            reward = self.balance - self.initial_balance\n",
    "\n",
    "        next_state = get_state(self.data, self.index) if not done else None\n",
    "        return next_state, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191dac75-bb78-4a66-96c9-7edda3346150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DQN is a neural network that approximates Q values for each state-action pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4cb1bb1-2dd0-4184-996b-31963267dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network with torch library\n",
    "# deep q-network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35511a00-7550-42f8-a917-ca5b7c78c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program a DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Discount factor\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = DQN(state_size, action_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(list(ACTIONS.keys()))\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_state_tensor = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "                target += self.gamma * torch.max(self.model(next_state_tensor)).item()\n",
    "\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            target_tensor = self.model(state_tensor).clone().detach()\n",
    "            target_tensor[0][action] = target\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(state_tensor)\n",
    "            loss = self.criterion(output, target_tensor)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5003b4a8-ca73-4517-a92b-fc3316775564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:5: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Close']),\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_5']),\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_20']),\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Returns'])\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\2354991637.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  price = float(self.data.loc[self.index, 'Close'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/500, Total Reward: 7278.934745788574\n",
      "Episode 2/500, Total Reward: -9821.325180053711\n",
      "Episode 3/500, Total Reward: -9894.329265594482\n",
      "Episode 4/500, Total Reward: -9852.625118255615\n",
      "Episode 5/500, Total Reward: -9903.610557556152\n",
      "Episode 6/500, Total Reward: -9800.343521118164\n",
      "Episode 7/500, Total Reward: -9917.574089050293\n",
      "Episode 8/500, Total Reward: -9848.722831726074\n",
      "Episode 9/500, Total Reward: 9314.805347442627\n",
      "Episode 10/500, Total Reward: -9928.986518859863\n",
      "Episode 11/500, Total Reward: 22824.507022857666\n",
      "Episode 12/500, Total Reward: -9873.130554199219\n",
      "Episode 13/500, Total Reward: -9881.269943237305\n",
      "Episode 14/500, Total Reward: -9924.079879760742\n",
      "Episode 15/500, Total Reward: -9942.645240783691\n",
      "Episode 16/500, Total Reward: -9878.154693603516\n",
      "Episode 17/500, Total Reward: -9826.156986236572\n",
      "Episode 18/500, Total Reward: -9863.679512023926\n",
      "Episode 19/500, Total Reward: -9859.195457458496\n",
      "Episode 20/500, Total Reward: -9913.834060668945\n",
      "Episode 21/500, Total Reward: 3682.966598510742\n",
      "Episode 22/500, Total Reward: -9934.275272369385\n",
      "Episode 23/500, Total Reward: -9759.944255828857\n",
      "Episode 24/500, Total Reward: -9822.302890777588\n",
      "Episode 25/500, Total Reward: -9841.785808563232\n",
      "Episode 26/500, Total Reward: -9892.180744171143\n",
      "Episode 27/500, Total Reward: -9934.219833374023\n",
      "Episode 28/500, Total Reward: -9919.258892059326\n",
      "Episode 29/500, Total Reward: -9806.795886993408\n",
      "Episode 30/500, Total Reward: -9834.891078948975\n",
      "Episode 31/500, Total Reward: -9957.134780883789\n",
      "Episode 32/500, Total Reward: -9742.330627441406\n",
      "Episode 33/500, Total Reward: -9752.221397399902\n",
      "Episode 34/500, Total Reward: -9829.51195526123\n",
      "Episode 35/500, Total Reward: -9879.499267578125\n",
      "Episode 36/500, Total Reward: -9801.764556884766\n",
      "Episode 37/500, Total Reward: -9785.25768661499\n",
      "Episode 38/500, Total Reward: -9850.471687316895\n",
      "Episode 39/500, Total Reward: -9845.603164672852\n",
      "Episode 40/500, Total Reward: -9935.33166885376\n",
      "Episode 41/500, Total Reward: -9889.760551452637\n",
      "Episode 42/500, Total Reward: 20727.439056396484\n",
      "Episode 43/500, Total Reward: -9866.328628540039\n",
      "Episode 44/500, Total Reward: -9766.78821182251\n",
      "Episode 45/500, Total Reward: -9878.231727600098\n",
      "Episode 46/500, Total Reward: -9895.802028656006\n",
      "Episode 47/500, Total Reward: -9796.460975646973\n",
      "Episode 48/500, Total Reward: -9822.550415039062\n",
      "Episode 49/500, Total Reward: -9786.191608428955\n",
      "Episode 50/500, Total Reward: -9941.492240905762\n",
      "Episode 51/500, Total Reward: -9937.751091003418\n",
      "Episode 52/500, Total Reward: -9871.093204498291\n",
      "Episode 53/500, Total Reward: -9971.133312225342\n",
      "Episode 54/500, Total Reward: -9872.154956817627\n",
      "Episode 55/500, Total Reward: -9882.527374267578\n",
      "Episode 56/500, Total Reward: -2495.4418716430664\n",
      "Episode 57/500, Total Reward: -9719.313529968262\n",
      "Episode 58/500, Total Reward: -9801.989002227783\n",
      "Episode 59/500, Total Reward: -9861.886333465576\n",
      "Episode 60/500, Total Reward: 1203.82027053833\n",
      "Episode 61/500, Total Reward: -9866.854587554932\n",
      "Episode 62/500, Total Reward: 5319.4337158203125\n",
      "Episode 63/500, Total Reward: -9820.581192016602\n",
      "Episode 64/500, Total Reward: -9822.014957427979\n",
      "Episode 65/500, Total Reward: -9832.9761428833\n",
      "Episode 66/500, Total Reward: -9904.434043884277\n",
      "Episode 67/500, Total Reward: -9932.573192596436\n",
      "Episode 68/500, Total Reward: -9999.262222290039\n",
      "Episode 69/500, Total Reward: 9909.802303314209\n",
      "Episode 70/500, Total Reward: 4008.929862976074\n",
      "Episode 71/500, Total Reward: -9833.687057495117\n",
      "Episode 72/500, Total Reward: -9951.888538360596\n",
      "Episode 73/500, Total Reward: -9873.43790435791\n",
      "Episode 74/500, Total Reward: -9988.943641662598\n",
      "Episode 75/500, Total Reward: -9937.496315002441\n",
      "Episode 76/500, Total Reward: 8832.087886810303\n",
      "Episode 77/500, Total Reward: -9800.199111938477\n",
      "Episode 78/500, Total Reward: 3155.081401824951\n",
      "Episode 79/500, Total Reward: -9824.035572052002\n",
      "Episode 80/500, Total Reward: -9838.53366470337\n",
      "Episode 81/500, Total Reward: 5393.006050109863\n",
      "Episode 82/500, Total Reward: -9919.98057937622\n",
      "Episode 83/500, Total Reward: 2025.573040008545\n",
      "Episode 84/500, Total Reward: -9855.079982757568\n",
      "Episode 85/500, Total Reward: -9990.466449737549\n",
      "Episode 86/500, Total Reward: -9750.800987243652\n",
      "Episode 87/500, Total Reward: -9823.54875946045\n",
      "Episode 88/500, Total Reward: -9859.517486572266\n",
      "Episode 89/500, Total Reward: -9848.998962402344\n",
      "Episode 90/500, Total Reward: 7413.168106079102\n",
      "Episode 91/500, Total Reward: 5461.896781921387\n",
      "Episode 92/500, Total Reward: -1658.8395690917969\n",
      "Episode 93/500, Total Reward: -9846.645767211914\n",
      "Episode 94/500, Total Reward: 7456.393520355225\n",
      "Episode 95/500, Total Reward: -9883.734924316406\n",
      "Episode 96/500, Total Reward: -9858.954803466797\n",
      "Episode 97/500, Total Reward: -9899.555236816406\n",
      "Episode 98/500, Total Reward: -9846.247524261475\n",
      "Episode 99/500, Total Reward: 17199.249588012695\n",
      "Episode 100/500, Total Reward: -9876.711837768555\n",
      "Episode 101/500, Total Reward: -9846.911487579346\n",
      "Episode 102/500, Total Reward: -1510.8785438537598\n",
      "Episode 103/500, Total Reward: -9877.227317810059\n",
      "Episode 104/500, Total Reward: -9811.129085540771\n",
      "Episode 105/500, Total Reward: -9855.945617675781\n",
      "Episode 106/500, Total Reward: 7330.2886962890625\n",
      "Episode 107/500, Total Reward: -9993.29627609253\n",
      "Episode 108/500, Total Reward: -9901.752094268799\n",
      "Episode 109/500, Total Reward: -9861.185562133789\n",
      "Episode 110/500, Total Reward: -9804.16870880127\n",
      "Episode 111/500, Total Reward: -9881.7412109375\n",
      "Episode 112/500, Total Reward: -9857.652290344238\n",
      "Episode 113/500, Total Reward: -9886.988876342773\n",
      "Episode 114/500, Total Reward: -9945.477066040039\n",
      "Episode 115/500, Total Reward: 9201.091510772705\n",
      "Episode 116/500, Total Reward: -9840.032455444336\n",
      "Episode 117/500, Total Reward: 685.0452575683594\n",
      "Episode 118/500, Total Reward: -9895.120407104492\n",
      "Episode 119/500, Total Reward: -9911.589450836182\n",
      "Episode 120/500, Total Reward: -763.3063812255859\n",
      "Episode 121/500, Total Reward: 499.7313423156738\n",
      "Episode 122/500, Total Reward: 2925.297576904297\n",
      "Episode 123/500, Total Reward: -9838.666137695312\n",
      "Episode 124/500, Total Reward: -9858.221328735352\n",
      "Episode 125/500, Total Reward: -9922.235889434814\n",
      "Episode 126/500, Total Reward: -68.75285339355469\n",
      "Episode 127/500, Total Reward: -9776.621803283691\n",
      "Episode 128/500, Total Reward: -9877.49526977539\n",
      "Episode 129/500, Total Reward: -9846.8070602417\n",
      "Episode 130/500, Total Reward: -9935.846221923828\n",
      "Episode 131/500, Total Reward: -9916.045639038086\n",
      "Episode 132/500, Total Reward: -9868.499549865723\n",
      "Episode 133/500, Total Reward: -9835.136219024658\n",
      "Episode 134/500, Total Reward: -9994.898235321045\n",
      "Episode 135/500, Total Reward: -9886.848209381104\n",
      "Episode 136/500, Total Reward: -9878.806858062744\n",
      "Episode 137/500, Total Reward: 2178.0032272338867\n",
      "Episode 138/500, Total Reward: -9916.346309661865\n",
      "Episode 139/500, Total Reward: -9793.015968322754\n",
      "Episode 140/500, Total Reward: -9982.749908447266\n",
      "Episode 141/500, Total Reward: 1186.2393684387207\n",
      "Episode 142/500, Total Reward: -9882.78762435913\n",
      "Episode 143/500, Total Reward: -9934.214748382568\n",
      "Episode 144/500, Total Reward: -9826.169151306152\n",
      "Episode 145/500, Total Reward: -9832.868591308594\n",
      "Episode 146/500, Total Reward: -9786.849250793457\n",
      "Episode 147/500, Total Reward: -9867.243495941162\n",
      "Episode 148/500, Total Reward: -9783.772232055664\n",
      "Episode 149/500, Total Reward: -9853.14580154419\n",
      "Episode 150/500, Total Reward: -9864.193920135498\n",
      "Episode 151/500, Total Reward: -9815.579635620117\n",
      "Episode 152/500, Total Reward: -9942.935974121094\n",
      "Episode 153/500, Total Reward: -9936.887027740479\n",
      "Episode 154/500, Total Reward: -9943.37675857544\n",
      "Episode 155/500, Total Reward: -9813.514022827148\n",
      "Episode 156/500, Total Reward: -9934.054721832275\n",
      "Episode 157/500, Total Reward: -9961.188804626465\n",
      "Episode 158/500, Total Reward: -9934.533729553223\n",
      "Episode 159/500, Total Reward: -9827.879173278809\n",
      "Episode 160/500, Total Reward: -9886.236892700195\n",
      "Episode 161/500, Total Reward: -9944.425369262695\n",
      "Episode 162/500, Total Reward: -9902.902286529541\n",
      "Episode 163/500, Total Reward: -9848.195457458496\n",
      "Episode 164/500, Total Reward: -9936.089473724365\n",
      "Episode 165/500, Total Reward: 14416.246795654297\n",
      "Episode 166/500, Total Reward: -9936.563735961914\n",
      "Episode 167/500, Total Reward: -9928.627227783203\n",
      "Episode 168/500, Total Reward: 366.2975769042969\n",
      "Episode 169/500, Total Reward: -9997.984531402588\n",
      "Episode 170/500, Total Reward: 4904.553985595703\n",
      "Episode 171/500, Total Reward: -9820.709041595459\n",
      "Episode 172/500, Total Reward: -1228.7942657470703\n",
      "Episode 173/500, Total Reward: -9825.85274887085\n",
      "Episode 174/500, Total Reward: -9969.357753753662\n",
      "Episode 175/500, Total Reward: -9988.099662780762\n",
      "Episode 176/500, Total Reward: -9872.266536712646\n",
      "Episode 177/500, Total Reward: 7423.884078979492\n",
      "Episode 178/500, Total Reward: 4408.435153961182\n",
      "Episode 179/500, Total Reward: -9875.95040512085\n",
      "Episode 180/500, Total Reward: -1506.0701370239258\n",
      "Episode 181/500, Total Reward: -9878.800617218018\n",
      "Episode 182/500, Total Reward: -9858.088245391846\n",
      "Episode 183/500, Total Reward: -9992.695049285889\n",
      "Episode 184/500, Total Reward: -9858.894309997559\n",
      "Episode 185/500, Total Reward: 13210.293045043945\n",
      "Episode 186/500, Total Reward: 2491.0622215270996\n",
      "Episode 187/500, Total Reward: -9856.594429016113\n",
      "Episode 188/500, Total Reward: -9938.75675201416\n",
      "Episode 189/500, Total Reward: -9861.1918258667\n",
      "Episode 190/500, Total Reward: -9931.249576568604\n",
      "Episode 191/500, Total Reward: -1453.439552307129\n",
      "Episode 192/500, Total Reward: -9932.933227539062\n",
      "Episode 193/500, Total Reward: 1616.248134613037\n",
      "Episode 194/500, Total Reward: -9894.358810424805\n",
      "Episode 195/500, Total Reward: -9971.77745437622\n",
      "Episode 196/500, Total Reward: -9997.251220703125\n",
      "Episode 197/500, Total Reward: -9831.363647460938\n",
      "Episode 198/500, Total Reward: -9941.503425598145\n",
      "Episode 199/500, Total Reward: -9798.838882446289\n",
      "Episode 200/500, Total Reward: -9971.903827667236\n",
      "Episode 201/500, Total Reward: -9991.153213500977\n",
      "Episode 202/500, Total Reward: -9866.997863769531\n",
      "Episode 203/500, Total Reward: -9762.475234985352\n",
      "Episode 204/500, Total Reward: -9805.135288238525\n",
      "Episode 205/500, Total Reward: -9800.508113861084\n",
      "Episode 206/500, Total Reward: -9998.95369720459\n",
      "Episode 207/500, Total Reward: -9871.760845184326\n",
      "Episode 208/500, Total Reward: -9816.511833190918\n",
      "Episode 209/500, Total Reward: -9792.573120117188\n",
      "Episode 210/500, Total Reward: -9844.080516815186\n",
      "Episode 211/500, Total Reward: -9836.097583770752\n",
      "Episode 212/500, Total Reward: -9859.071647644043\n",
      "Episode 213/500, Total Reward: -9985.351303100586\n",
      "Episode 214/500, Total Reward: 2754.2789154052734\n",
      "Episode 215/500, Total Reward: 2165.3216514587402\n",
      "Episode 216/500, Total Reward: 5759.413749694824\n",
      "Episode 217/500, Total Reward: -2734.9411697387695\n",
      "Episode 218/500, Total Reward: 4801.421504974365\n",
      "Episode 219/500, Total Reward: -9822.266632080078\n",
      "Episode 220/500, Total Reward: 6473.366004943848\n",
      "Episode 221/500, Total Reward: -9775.277641296387\n",
      "Episode 222/500, Total Reward: -9971.658153533936\n",
      "Episode 223/500, Total Reward: 2092.7992973327637\n",
      "Episode 224/500, Total Reward: -9815.595176696777\n",
      "Episode 225/500, Total Reward: -9755.859531402588\n",
      "Episode 226/500, Total Reward: -9932.50454711914\n",
      "Episode 227/500, Total Reward: -9926.224784851074\n",
      "Episode 228/500, Total Reward: -9904.826824188232\n",
      "Episode 229/500, Total Reward: -9899.682815551758\n",
      "Episode 230/500, Total Reward: -9857.846561431885\n",
      "Episode 231/500, Total Reward: -9830.278873443604\n",
      "Episode 232/500, Total Reward: -9992.492149353027\n",
      "Episode 233/500, Total Reward: -9754.576271057129\n",
      "Episode 234/500, Total Reward: -9917.725845336914\n",
      "Episode 235/500, Total Reward: -9854.885871887207\n",
      "Episode 236/500, Total Reward: -9755.963470458984\n",
      "Episode 237/500, Total Reward: -9834.146949768066\n",
      "Episode 238/500, Total Reward: -9844.002418518066\n",
      "Episode 239/500, Total Reward: -9954.094612121582\n",
      "Episode 240/500, Total Reward: -9731.491306304932\n",
      "Episode 241/500, Total Reward: -9826.013053894043\n",
      "Episode 242/500, Total Reward: -9787.23226928711\n",
      "Episode 243/500, Total Reward: -1600.7164192199707\n",
      "Episode 244/500, Total Reward: -4486.007614135742\n",
      "Episode 245/500, Total Reward: -9938.470935821533\n",
      "Episode 246/500, Total Reward: -9852.191661834717\n",
      "Episode 247/500, Total Reward: -9868.65079498291\n",
      "Episode 248/500, Total Reward: -9939.81763458252\n",
      "Episode 249/500, Total Reward: -9837.068992614746\n",
      "Episode 250/500, Total Reward: -9827.670551300049\n",
      "Episode 251/500, Total Reward: -9992.521514892578\n",
      "Episode 252/500, Total Reward: -9940.376560211182\n",
      "Episode 253/500, Total Reward: -9879.316413879395\n",
      "Episode 254/500, Total Reward: -9865.442440032959\n",
      "Episode 255/500, Total Reward: -9988.167427062988\n",
      "Episode 256/500, Total Reward: 8475.084686279297\n",
      "Episode 257/500, Total Reward: -9941.597896575928\n",
      "Episode 258/500, Total Reward: -9994.756801605225\n",
      "Episode 259/500, Total Reward: -9932.832107543945\n",
      "Episode 260/500, Total Reward: -9932.473850250244\n",
      "Episode 261/500, Total Reward: -9991.14217376709\n",
      "Episode 262/500, Total Reward: -9871.210544586182\n",
      "Episode 263/500, Total Reward: -9982.08447265625\n",
      "Episode 264/500, Total Reward: -9927.4743309021\n",
      "Episode 265/500, Total Reward: -9925.71418762207\n",
      "Episode 266/500, Total Reward: -9950.839111328125\n",
      "Episode 267/500, Total Reward: -9936.958011627197\n",
      "Episode 268/500, Total Reward: 3507.2617721557617\n",
      "Episode 269/500, Total Reward: -9894.875930786133\n",
      "Episode 270/500, Total Reward: -696.2868919372559\n",
      "Episode 271/500, Total Reward: -9940.51156616211\n",
      "Episode 272/500, Total Reward: -9993.248161315918\n",
      "Episode 273/500, Total Reward: -9810.944473266602\n",
      "Episode 274/500, Total Reward: 2782.930965423584\n",
      "Episode 275/500, Total Reward: 5700.870712280273\n",
      "Episode 276/500, Total Reward: -9907.68138885498\n",
      "Episode 277/500, Total Reward: -9917.83822631836\n",
      "Episode 278/500, Total Reward: 428.3009033203125\n",
      "Episode 279/500, Total Reward: 11956.81912612915\n",
      "Episode 280/500, Total Reward: -9906.240673065186\n",
      "Episode 281/500, Total Reward: -9993.077819824219\n",
      "Episode 282/500, Total Reward: -9914.04653930664\n",
      "Episode 283/500, Total Reward: 3758.977153778076\n",
      "Episode 284/500, Total Reward: -9929.719116210938\n",
      "Episode 285/500, Total Reward: -9910.318489074707\n",
      "Episode 286/500, Total Reward: -9873.349910736084\n",
      "Episode 287/500, Total Reward: -9865.118461608887\n",
      "Episode 288/500, Total Reward: -9787.187381744385\n",
      "Episode 289/500, Total Reward: -9758.08893585205\n",
      "Episode 290/500, Total Reward: -9995.031089782715\n",
      "Episode 291/500, Total Reward: -9909.265407562256\n",
      "Episode 292/500, Total Reward: -9795.89113998413\n",
      "Episode 293/500, Total Reward: -9989.70189666748\n",
      "Episode 294/500, Total Reward: -9869.862800598145\n",
      "Episode 295/500, Total Reward: -9944.207103729248\n",
      "Episode 296/500, Total Reward: -627.5888900756836\n",
      "Episode 297/500, Total Reward: -9945.330619812012\n",
      "Episode 298/500, Total Reward: -9755.84398651123\n",
      "Episode 299/500, Total Reward: -9751.177104949951\n",
      "Episode 300/500, Total Reward: -9921.630149841309\n",
      "Episode 301/500, Total Reward: -9857.273094177246\n",
      "Episode 302/500, Total Reward: 5625.266883850098\n",
      "Episode 303/500, Total Reward: -9854.587425231934\n",
      "Episode 304/500, Total Reward: -9790.204574584961\n",
      "Episode 305/500, Total Reward: -9824.625522613525\n",
      "Episode 306/500, Total Reward: 131.0361557006836\n",
      "Episode 307/500, Total Reward: 2671.1828231811523\n",
      "Episode 308/500, Total Reward: 1195.7210540771484\n",
      "Episode 309/500, Total Reward: -857.9581985473633\n",
      "Episode 310/500, Total Reward: -523.3933372497559\n",
      "Episode 311/500, Total Reward: 3443.129081726074\n",
      "Episode 312/500, Total Reward: 3135.863052368164\n",
      "Episode 313/500, Total Reward: -1468.6237258911133\n",
      "Episode 314/500, Total Reward: 373.7203063964844\n",
      "Episode 315/500, Total Reward: 1955.8830490112305\n",
      "Episode 316/500, Total Reward: 4314.558250427246\n",
      "Episode 317/500, Total Reward: 3312.73539352417\n",
      "Episode 318/500, Total Reward: 3241.231735229492\n",
      "Episode 319/500, Total Reward: 4877.766380310059\n",
      "Episode 320/500, Total Reward: 833.6281433105469\n",
      "Episode 321/500, Total Reward: 5675.531547546387\n",
      "Episode 322/500, Total Reward: 1684.9303283691406\n",
      "Episode 323/500, Total Reward: -1909.2425651550293\n",
      "Episode 324/500, Total Reward: 2592.133502960205\n",
      "Episode 325/500, Total Reward: 7360.892803192139\n",
      "Episode 326/500, Total Reward: 9078.275157928467\n",
      "Episode 327/500, Total Reward: 3539.1115798950195\n",
      "Episode 328/500, Total Reward: 2777.833251953125\n",
      "Episode 329/500, Total Reward: 5795.068618774414\n",
      "Episode 330/500, Total Reward: 3034.972873687744\n",
      "Episode 331/500, Total Reward: -9929.490242004395\n",
      "Episode 332/500, Total Reward: 5590.9237632751465\n",
      "Episode 333/500, Total Reward: -9981.87088394165\n",
      "Episode 334/500, Total Reward: 4522.680892944336\n",
      "Episode 335/500, Total Reward: -9915.824180603027\n",
      "Episode 336/500, Total Reward: -9784.875846862793\n",
      "Episode 337/500, Total Reward: -9842.331722259521\n",
      "Episode 338/500, Total Reward: -9931.692958831787\n",
      "Episode 339/500, Total Reward: 8922.674575805664\n",
      "Episode 340/500, Total Reward: 3795.1929893493652\n",
      "Episode 341/500, Total Reward: -9981.263423919678\n",
      "Episode 342/500, Total Reward: 5266.798778533936\n",
      "Episode 343/500, Total Reward: 13377.231121063232\n",
      "Episode 344/500, Total Reward: 3870.244655609131\n",
      "Episode 345/500, Total Reward: 9147.614391326904\n",
      "Episode 346/500, Total Reward: -9796.987117767334\n",
      "Episode 347/500, Total Reward: -9835.9596824646\n",
      "Episode 348/500, Total Reward: 12769.31192779541\n",
      "Episode 349/500, Total Reward: -9892.474723815918\n",
      "Episode 350/500, Total Reward: -9825.453117370605\n",
      "Episode 351/500, Total Reward: -9885.60610961914\n",
      "Episode 352/500, Total Reward: -9988.22787475586\n",
      "Episode 353/500, Total Reward: -9846.062705993652\n",
      "Episode 354/500, Total Reward: -9828.372535705566\n",
      "Episode 355/500, Total Reward: -9984.293533325195\n",
      "Episode 356/500, Total Reward: -9875.13430404663\n",
      "Episode 357/500, Total Reward: -9788.688236236572\n",
      "Episode 358/500, Total Reward: 3226.6044006347656\n",
      "Episode 359/500, Total Reward: -9802.126689910889\n",
      "Episode 360/500, Total Reward: 2179.3745193481445\n",
      "Episode 361/500, Total Reward: 8072.7187576293945\n",
      "Episode 362/500, Total Reward: -640.0737228393555\n",
      "Episode 363/500, Total Reward: -9840.355209350586\n",
      "Episode 364/500, Total Reward: 2095.8137702941895\n",
      "Episode 365/500, Total Reward: -744.2117080688477\n",
      "Episode 366/500, Total Reward: -1628.0968551635742\n",
      "Episode 372/500, Total Reward: -9991.29455947876\n",
      "Episode 373/500, Total Reward: -9876.921695709229\n",
      "Episode 374/500, Total Reward: 7006.0794677734375\n",
      "Episode 375/500, Total Reward: -9777.110256195068\n",
      "Episode 376/500, Total Reward: -9856.669914245605\n",
      "Episode 377/500, Total Reward: 11940.932563781738\n",
      "Episode 378/500, Total Reward: -9839.10103225708\n",
      "Episode 379/500, Total Reward: 5884.291088104248\n",
      "Episode 380/500, Total Reward: 8981.669242858887\n",
      "Episode 381/500, Total Reward: -9821.675838470459\n",
      "Episode 382/500, Total Reward: -9790.746269226074\n",
      "Episode 383/500, Total Reward: -9830.582656860352\n",
      "Episode 384/500, Total Reward: 11114.725997924805\n",
      "Episode 385/500, Total Reward: -9781.996391296387\n",
      "Episode 386/500, Total Reward: -9888.86022567749\n",
      "Episode 387/500, Total Reward: -9845.239852905273\n",
      "Episode 388/500, Total Reward: 6585.117794036865\n",
      "Episode 389/500, Total Reward: 2653.1353874206543\n",
      "Episode 390/500, Total Reward: -9912.561073303223\n",
      "Episode 391/500, Total Reward: -9743.838832855225\n",
      "Episode 392/500, Total Reward: 13320.634510040283\n",
      "Episode 393/500, Total Reward: -9766.987606048584\n",
      "Episode 394/500, Total Reward: 13474.615333557129\n",
      "Episode 395/500, Total Reward: -9908.09976196289\n",
      "Episode 396/500, Total Reward: 11705.853939056396\n",
      "Episode 397/500, Total Reward: 17160.3335647583\n",
      "Episode 398/500, Total Reward: -9888.734832763672\n",
      "Episode 399/500, Total Reward: -9999.954532623291\n",
      "Episode 400/500, Total Reward: 8714.382499694824\n",
      "Episode 401/500, Total Reward: 10831.003684997559\n",
      "Episode 402/500, Total Reward: 13487.656147003174\n",
      "Episode 403/500, Total Reward: 13633.410427093506\n",
      "Episode 404/500, Total Reward: 11641.0658493042\n",
      "Episode 405/500, Total Reward: -9828.28917312622\n",
      "Episode 406/500, Total Reward: 14337.77169418335\n",
      "Episode 407/500, Total Reward: 5836.152565002441\n",
      "Episode 408/500, Total Reward: 5050.5677490234375\n",
      "Episode 409/500, Total Reward: -894.3578109741211\n",
      "Episode 410/500, Total Reward: -2619.1117248535156\n",
      "Episode 411/500, Total Reward: -1201.4214706420898\n",
      "Episode 412/500, Total Reward: 1018.9632873535156\n",
      "Episode 413/500, Total Reward: -9923.775924682617\n",
      "Episode 414/500, Total Reward: -1665.164192199707\n",
      "Episode 415/500, Total Reward: -9794.227043151855\n",
      "Episode 416/500, Total Reward: -9885.183193206787\n",
      "Episode 417/500, Total Reward: 6946.1134033203125\n",
      "Episode 418/500, Total Reward: 11192.681980133057\n",
      "Episode 419/500, Total Reward: -9916.200584411621\n",
      "Episode 420/500, Total Reward: 10718.502128601074\n",
      "Episode 421/500, Total Reward: 7902.480819702148\n",
      "Episode 422/500, Total Reward: 16317.991195678711\n",
      "Episode 423/500, Total Reward: 3397.147045135498\n",
      "Episode 424/500, Total Reward: 13091.689346313477\n",
      "Episode 425/500, Total Reward: 3434.144100189209\n",
      "Episode 426/500, Total Reward: -9846.759536743164\n",
      "Episode 427/500, Total Reward: -9941.604515075684\n",
      "Episode 428/500, Total Reward: 2315.2196197509766\n",
      "Episode 429/500, Total Reward: 400.15247344970703\n",
      "Episode 430/500, Total Reward: -44.41334915161133\n",
      "Episode 431/500, Total Reward: -721.9926223754883\n",
      "Episode 432/500, Total Reward: 6678.140731811523\n",
      "Episode 433/500, Total Reward: 145.65167999267578\n",
      "Episode 434/500, Total Reward: 244.69006729125977\n",
      "Episode 435/500, Total Reward: 7654.544002532959\n",
      "Episode 436/500, Total Reward: -536.9748458862305\n",
      "Episode 437/500, Total Reward: 939.8043594360352\n",
      "Episode 438/500, Total Reward: -9924.530754089355\n",
      "Episode 439/500, Total Reward: -9827.699375152588\n",
      "Episode 440/500, Total Reward: -9853.788879394531\n",
      "Episode 441/500, Total Reward: 2036.7357559204102\n",
      "Episode 442/500, Total Reward: -9998.872653961182\n",
      "Episode 443/500, Total Reward: 6383.285968780518\n",
      "Episode 444/500, Total Reward: 16092.404125213623\n",
      "Episode 445/500, Total Reward: -9797.915588378906\n",
      "Episode 446/500, Total Reward: -9978.298927307129\n",
      "Episode 447/500, Total Reward: 13326.402236938477\n",
      "Episode 448/500, Total Reward: 7986.702766418457\n",
      "Episode 449/500, Total Reward: -9874.891944885254\n",
      "Episode 450/500, Total Reward: -9984.427547454834\n",
      "Episode 451/500, Total Reward: 1946.2180137634277\n",
      "Episode 452/500, Total Reward: -1250.852653503418\n",
      "Episode 453/500, Total Reward: 1629.2266235351562\n",
      "Episode 454/500, Total Reward: -9831.177089691162\n",
      "Episode 455/500, Total Reward: 792.6252136230469\n",
      "Episode 456/500, Total Reward: 347.44043731689453\n",
      "Episode 457/500, Total Reward: 796.0838775634766\n",
      "Episode 458/500, Total Reward: -1049.235279083252\n",
      "Episode 459/500, Total Reward: -9929.818000793457\n",
      "Episode 460/500, Total Reward: -1015.6119232177734\n",
      "Episode 461/500, Total Reward: -1094.2704772949219\n",
      "Episode 462/500, Total Reward: -268.50661849975586\n",
      "Episode 463/500, Total Reward: 1943.7137145996094\n",
      "Episode 464/500, Total Reward: -9921.94571685791\n",
      "Episode 465/500, Total Reward: 2726.6550903320312\n",
      "Episode 466/500, Total Reward: -9829.680801391602\n",
      "Episode 467/500, Total Reward: 978.5837707519531\n",
      "Episode 468/500, Total Reward: -379.041202545166\n",
      "Episode 469/500, Total Reward: -947.2982864379883\n",
      "Episode 470/500, Total Reward: 3184.500991821289\n",
      "Episode 471/500, Total Reward: 24110.274963378906\n",
      "Episode 472/500, Total Reward: 2672.211582183838\n",
      "Episode 473/500, Total Reward: 370.5687561035156\n",
      "Episode 474/500, Total Reward: 425.6351318359375\n",
      "Episode 475/500, Total Reward: -9777.732795715332\n",
      "Episode 476/500, Total Reward: -9843.545070648193\n",
      "Episode 477/500, Total Reward: 3960.3329277038574\n",
      "Episode 478/500, Total Reward: -9792.22356414795\n",
      "Episode 479/500, Total Reward: 6439.429756164551\n",
      "Episode 480/500, Total Reward: -9956.64841079712\n",
      "Episode 481/500, Total Reward: -9995.184944152832\n",
      "Episode 482/500, Total Reward: 572.3609313964844\n",
      "Episode 483/500, Total Reward: -9906.748638153076\n",
      "Episode 484/500, Total Reward: 8550.319366455078\n",
      "Episode 485/500, Total Reward: -9805.725410461426\n",
      "Episode 486/500, Total Reward: -9927.758331298828\n",
      "Episode 487/500, Total Reward: 1202.4941749572754\n",
      "Episode 488/500, Total Reward: -9941.203647613525\n",
      "Episode 489/500, Total Reward: -9879.109722137451\n",
      "Episode 490/500, Total Reward: -9886.200775146484\n",
      "Episode 491/500, Total Reward: -585.4882774353027\n",
      "Episode 492/500, Total Reward: 9054.19605255127\n",
      "Episode 493/500, Total Reward: -9772.294647216797\n",
      "Episode 494/500, Total Reward: 3566.320442199707\n",
      "Episode 495/500, Total Reward: -9924.689445495605\n",
      "Episode 496/500, Total Reward: 915.209114074707\n",
      "Episode 497/500, Total Reward: -9891.904838562012\n",
      "Episode 498/500, Total Reward: 3733.334815979004\n",
      "Episode 499/500, Total Reward: -9836.371192932129\n",
      "Episode 500/500, Total Reward: 3031.8487281799316\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# Train the agent for its capabilities\n",
    "# Program the environment as well\n",
    "env = TradingEnvironment(data)\n",
    "agent = DQNAgent(state_size=4, action_size=3)\n",
    "batch_size = 32\n",
    "episodes = 500\n",
    "total_rewards = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    agent.replay(batch_size)\n",
    "    total_rewards.append(total_reward)\n",
    "    print(f\"Episode {episode+1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cdf2cbb-7913-4c3f-bec9-b8382238f3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:5: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Close']),\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_5']),\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_20']),\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\4234187306.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Returns'])\n",
      "C:\\Users\\megaw\\AppData\\Local\\Temp\\ipykernel_29040\\2354991637.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  price = float(self.data.loc[self.index, 'Close'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balance after testing: $228.16\n",
      "Total Profit: $-9771.84\n"
     ]
    }
   ],
   "source": [
    "# create a new environment situation for testing\n",
    "test_env = TradingEnvironment(data)\n",
    "state = test_env.reset()\n",
    "done = False\n",
    "\n",
    "# simulate a trading session using the trained agent\n",
    "while not done:\n",
    "    # always choose the best action (exploitation)\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _ = test_env.step(action)\n",
    "    state = next_state if next_state is not None else state\n",
    "# Calculation with the reward function(s)\n",
    "final_balance = test_env.balance\n",
    "profit = final_balance - test_env.initial_balance\n",
    "print(f\"Final Balance after testing: ${final_balance:.2f}\")\n",
    "print(f\"Total Profit: ${profit:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3530f-924a-41f3-b034-b7bf685ee9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67373f-8e56-4c36-85cb-deea15429d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
